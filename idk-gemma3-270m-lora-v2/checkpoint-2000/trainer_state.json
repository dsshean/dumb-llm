{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5333688912594173,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006667111140742716,
      "grad_norm": 29.17045021057129,
      "learning_rate": 2.4e-05,
      "loss": 9.0132,
      "step": 25
    },
    {
      "epoch": 0.013334222281485432,
      "grad_norm": 5.940922260284424,
      "learning_rate": 4.9e-05,
      "loss": 3.1085,
      "step": 50
    },
    {
      "epoch": 0.020001333422228148,
      "grad_norm": 4.75091028213501,
      "learning_rate": 7.4e-05,
      "loss": 0.8361,
      "step": 75
    },
    {
      "epoch": 0.026668444562970864,
      "grad_norm": 5.481151580810547,
      "learning_rate": 9.900000000000001e-05,
      "loss": 0.3888,
      "step": 100
    },
    {
      "epoch": 0.03333555570371358,
      "grad_norm": 4.8530707359313965,
      "learning_rate": 9.996063610703137e-05,
      "loss": 0.0894,
      "step": 125
    },
    {
      "epoch": 0.040002666844456296,
      "grad_norm": 0.14460884034633636,
      "learning_rate": 9.983598365438902e-05,
      "loss": 0.0255,
      "step": 150
    },
    {
      "epoch": 0.046669777985199015,
      "grad_norm": 1.6174122095108032,
      "learning_rate": 9.962618725965196e-05,
      "loss": 0.0128,
      "step": 175
    },
    {
      "epoch": 0.05333688912594173,
      "grad_norm": 0.7925379276275635,
      "learning_rate": 9.93316053564413e-05,
      "loss": 0.0132,
      "step": 200
    },
    {
      "epoch": 0.06000400026668445,
      "grad_norm": 0.902216374874115,
      "learning_rate": 9.895274123299723e-05,
      "loss": 0.0086,
      "step": 225
    },
    {
      "epoch": 0.06667111140742717,
      "grad_norm": 0.7504492402076721,
      "learning_rate": 9.849024217231935e-05,
      "loss": 0.0071,
      "step": 250
    },
    {
      "epoch": 0.07333822254816988,
      "grad_norm": 0.06608360260725021,
      "learning_rate": 9.794489834629455e-05,
      "loss": 0.0075,
      "step": 275
    },
    {
      "epoch": 0.08000533368891259,
      "grad_norm": 0.23566454648971558,
      "learning_rate": 9.731764146570173e-05,
      "loss": 0.0036,
      "step": 300
    },
    {
      "epoch": 0.0866724448296553,
      "grad_norm": 0.46256589889526367,
      "learning_rate": 9.660954318839933e-05,
      "loss": 0.0075,
      "step": 325
    },
    {
      "epoch": 0.09333955597039803,
      "grad_norm": 0.05447576195001602,
      "learning_rate": 9.582181328841611e-05,
      "loss": 0.0073,
      "step": 350
    },
    {
      "epoch": 0.10000666711114074,
      "grad_norm": 0.56997150182724,
      "learning_rate": 9.49557975890723e-05,
      "loss": 0.007,
      "step": 375
    },
    {
      "epoch": 0.10667377825188346,
      "grad_norm": 0.33683210611343384,
      "learning_rate": 9.401297566366318e-05,
      "loss": 0.0086,
      "step": 400
    },
    {
      "epoch": 0.11334088939262618,
      "grad_norm": 0.49612849950790405,
      "learning_rate": 9.299495830763286e-05,
      "loss": 0.005,
      "step": 425
    },
    {
      "epoch": 0.1200080005333689,
      "grad_norm": 0.9599058628082275,
      "learning_rate": 9.190348478655724e-05,
      "loss": 0.0082,
      "step": 450
    },
    {
      "epoch": 0.1266751116741116,
      "grad_norm": 0.23278631269931793,
      "learning_rate": 9.074041986463808e-05,
      "loss": 0.0065,
      "step": 475
    },
    {
      "epoch": 0.13334222281485433,
      "grad_norm": 0.12749271094799042,
      "learning_rate": 8.950775061878453e-05,
      "loss": 0.0071,
      "step": 500
    },
    {
      "epoch": 0.14000933395559703,
      "grad_norm": 0.007482727523893118,
      "learning_rate": 8.820758304372557e-05,
      "loss": 0.0079,
      "step": 525
    },
    {
      "epoch": 0.14667644509633976,
      "grad_norm": 0.19967956840991974,
      "learning_rate": 8.684213845395339e-05,
      "loss": 0.0069,
      "step": 550
    },
    {
      "epoch": 0.15334355623708248,
      "grad_norm": 0.2647906541824341,
      "learning_rate": 8.541374968864487e-05,
      "loss": 0.0062,
      "step": 575
    },
    {
      "epoch": 0.16001066737782518,
      "grad_norm": 0.4317331612110138,
      "learning_rate": 8.392485712604483e-05,
      "loss": 0.0073,
      "step": 600
    },
    {
      "epoch": 0.1666777785185679,
      "grad_norm": 0.16436880826950073,
      "learning_rate": 8.237800451412095e-05,
      "loss": 0.0055,
      "step": 625
    },
    {
      "epoch": 0.1733448896593106,
      "grad_norm": 0.1287333369255066,
      "learning_rate": 8.077583462461283e-05,
      "loss": 0.0047,
      "step": 650
    },
    {
      "epoch": 0.18001200080005333,
      "grad_norm": 0.313889741897583,
      "learning_rate": 7.912108473790092e-05,
      "loss": 0.005,
      "step": 675
    },
    {
      "epoch": 0.18667911194079606,
      "grad_norm": 0.10527089238166809,
      "learning_rate": 7.741658196640892e-05,
      "loss": 0.0058,
      "step": 700
    },
    {
      "epoch": 0.19334622308153876,
      "grad_norm": 0.0030187207739800215,
      "learning_rate": 7.566523842452958e-05,
      "loss": 0.0059,
      "step": 725
    },
    {
      "epoch": 0.20001333422228149,
      "grad_norm": 0.22043593227863312,
      "learning_rate": 7.387004625332608e-05,
      "loss": 0.0047,
      "step": 750
    },
    {
      "epoch": 0.2066804453630242,
      "grad_norm": 0.2457481026649475,
      "learning_rate": 7.203407250850928e-05,
      "loss": 0.0052,
      "step": 775
    },
    {
      "epoch": 0.2133475565037669,
      "grad_norm": 0.003365908982232213,
      "learning_rate": 7.016045392042452e-05,
      "loss": 0.0056,
      "step": 800
    },
    {
      "epoch": 0.22001466764450964,
      "grad_norm": 0.4016326665878296,
      "learning_rate": 6.825239153500029e-05,
      "loss": 0.0045,
      "step": 825
    },
    {
      "epoch": 0.22668177878525236,
      "grad_norm": 0.0034847622737288475,
      "learning_rate": 6.631314524481513e-05,
      "loss": 0.0043,
      "step": 850
    },
    {
      "epoch": 0.23334888992599506,
      "grad_norm": 0.05464481562376022,
      "learning_rate": 6.43460282196257e-05,
      "loss": 0.0058,
      "step": 875
    },
    {
      "epoch": 0.2400160010667378,
      "grad_norm": 0.12439847737550735,
      "learning_rate": 6.235440124587198e-05,
      "loss": 0.0053,
      "step": 900
    },
    {
      "epoch": 0.2466831122074805,
      "grad_norm": 0.30282771587371826,
      "learning_rate": 6.034166698482984e-05,
      "loss": 0.0052,
      "step": 925
    },
    {
      "epoch": 0.2533502233482232,
      "grad_norm": 0.1723300963640213,
      "learning_rate": 5.831126415922148e-05,
      "loss": 0.0048,
      "step": 950
    },
    {
      "epoch": 0.2600173344889659,
      "grad_norm": 0.06715237349271774,
      "learning_rate": 5.6266661678215216e-05,
      "loss": 0.005,
      "step": 975
    },
    {
      "epoch": 0.26668444562970867,
      "grad_norm": 0.00240751588717103,
      "learning_rate": 5.4211352710852495e-05,
      "loss": 0.0063,
      "step": 1000
    },
    {
      "epoch": 0.27335155677045136,
      "grad_norm": 0.30855873227119446,
      "learning_rate": 5.214884871802703e-05,
      "loss": 0.0044,
      "step": 1025
    },
    {
      "epoch": 0.28001866791119406,
      "grad_norm": 0.2172737866640091,
      "learning_rate": 5.0082673453212914e-05,
      "loss": 0.0053,
      "step": 1050
    },
    {
      "epoch": 0.2866857790519368,
      "grad_norm": 0.25836053490638733,
      "learning_rate": 4.801635694219079e-05,
      "loss": 0.0048,
      "step": 1075
    },
    {
      "epoch": 0.2933528901926795,
      "grad_norm": 0.09733787924051285,
      "learning_rate": 4.5953429452058135e-05,
      "loss": 0.0039,
      "step": 1100
    },
    {
      "epoch": 0.3000200013334222,
      "grad_norm": 0.2092735916376114,
      "learning_rate": 4.3897415459827e-05,
      "loss": 0.0057,
      "step": 1125
    },
    {
      "epoch": 0.30668711247416497,
      "grad_norm": 0.07951542735099792,
      "learning_rate": 4.1851827630914305e-05,
      "loss": 0.0053,
      "step": 1150
    },
    {
      "epoch": 0.31335422361490767,
      "grad_norm": 0.1614968478679657,
      "learning_rate": 3.982016081781189e-05,
      "loss": 0.0052,
      "step": 1175
    },
    {
      "epoch": 0.32002133475565037,
      "grad_norm": 0.29644477367401123,
      "learning_rate": 3.780588608918947e-05,
      "loss": 0.0041,
      "step": 1200
    },
    {
      "epoch": 0.3266884458963931,
      "grad_norm": 0.18246281147003174,
      "learning_rate": 3.581244479963225e-05,
      "loss": 0.0035,
      "step": 1225
    },
    {
      "epoch": 0.3333555570371358,
      "grad_norm": 0.0975254625082016,
      "learning_rate": 3.384324271014429e-05,
      "loss": 0.0042,
      "step": 1250
    },
    {
      "epoch": 0.3400226681778785,
      "grad_norm": 0.09697846323251724,
      "learning_rate": 3.190164416946285e-05,
      "loss": 0.0047,
      "step": 1275
    },
    {
      "epoch": 0.3466897793186212,
      "grad_norm": 0.001921689952723682,
      "learning_rate": 2.999096636612518e-05,
      "loss": 0.0055,
      "step": 1300
    },
    {
      "epoch": 0.35335689045936397,
      "grad_norm": 0.22522848844528198,
      "learning_rate": 2.811447366110741e-05,
      "loss": 0.0063,
      "step": 1325
    },
    {
      "epoch": 0.36002400160010667,
      "grad_norm": 0.1789545714855194,
      "learning_rate": 2.6275372010718635e-05,
      "loss": 0.0046,
      "step": 1350
    },
    {
      "epoch": 0.36669111274084937,
      "grad_norm": 0.13307633996009827,
      "learning_rate": 2.447680348927837e-05,
      "loss": 0.0053,
      "step": 1375
    },
    {
      "epoch": 0.3733582238815921,
      "grad_norm": 0.16838796436786652,
      "learning_rate": 2.2721840920935196e-05,
      "loss": 0.0043,
      "step": 1400
    },
    {
      "epoch": 0.3800253350223348,
      "grad_norm": 0.18310724198818207,
      "learning_rate": 2.1013482629798333e-05,
      "loss": 0.0046,
      "step": 1425
    },
    {
      "epoch": 0.3866924461630775,
      "grad_norm": 0.15536299347877502,
      "learning_rate": 1.9354647317351188e-05,
      "loss": 0.0052,
      "step": 1450
    },
    {
      "epoch": 0.3933595573038203,
      "grad_norm": 0.19363728165626526,
      "learning_rate": 1.774816907589873e-05,
      "loss": 0.005,
      "step": 1475
    },
    {
      "epoch": 0.40002666844456297,
      "grad_norm": 0.10824410617351532,
      "learning_rate": 1.6196792546568472e-05,
      "loss": 0.0048,
      "step": 1500
    },
    {
      "epoch": 0.40669377958530567,
      "grad_norm": 0.10125262290239334,
      "learning_rate": 1.470316823013707e-05,
      "loss": 0.0056,
      "step": 1525
    },
    {
      "epoch": 0.4133608907260484,
      "grad_norm": 0.21208371222019196,
      "learning_rate": 1.3269847958694153e-05,
      "loss": 0.0035,
      "step": 1550
    },
    {
      "epoch": 0.4200280018667911,
      "grad_norm": 0.3783445358276367,
      "learning_rate": 1.1899280535880119e-05,
      "loss": 0.0046,
      "step": 1575
    },
    {
      "epoch": 0.4266951130075338,
      "grad_norm": 0.0013950413558632135,
      "learning_rate": 1.059380755314613e-05,
      "loss": 0.004,
      "step": 1600
    },
    {
      "epoch": 0.4333622241482766,
      "grad_norm": 0.16120462119579315,
      "learning_rate": 9.355659389184396e-06,
      "loss": 0.004,
      "step": 1625
    },
    {
      "epoch": 0.4400293352890193,
      "grad_norm": 0.19846472144126892,
      "learning_rate": 8.186951399363613e-06,
      "loss": 0.0041,
      "step": 1650
    },
    {
      "epoch": 0.446696446429762,
      "grad_norm": 0.04771341010928154,
      "learning_rate": 7.089680301679752e-06,
      "loss": 0.0034,
      "step": 1675
    },
    {
      "epoch": 0.4533635575705047,
      "grad_norm": 0.30732542276382446,
      "learning_rate": 6.0657207653969315e-06,
      "loss": 0.0037,
      "step": 1700
    },
    {
      "epoch": 0.4600306687112474,
      "grad_norm": 0.14373444020748138,
      "learning_rate": 5.116822208206396e-06,
      "loss": 0.0056,
      "step": 1725
    },
    {
      "epoch": 0.4666977798519901,
      "grad_norm": 0.001218448975123465,
      "learning_rate": 4.244605807375679e-06,
      "loss": 0.0053,
      "step": 1750
    },
    {
      "epoch": 0.4733648909927328,
      "grad_norm": 0.16144295036792755,
      "learning_rate": 3.4505617299945336e-06,
      "loss": 0.0044,
      "step": 1775
    },
    {
      "epoch": 0.4800320021334756,
      "grad_norm": 0.1389831155538559,
      "learning_rate": 2.73604658704939e-06,
      "loss": 0.004,
      "step": 1800
    },
    {
      "epoch": 0.4866991132742183,
      "grad_norm": 0.001287491642870009,
      "learning_rate": 2.102281115676258e-06,
      "loss": 0.0049,
      "step": 1825
    },
    {
      "epoch": 0.493366224414961,
      "grad_norm": 0.002464116318151355,
      "learning_rate": 1.550348093551829e-06,
      "loss": 0.0049,
      "step": 1850
    },
    {
      "epoch": 0.5000333355557037,
      "grad_norm": 0.0014503636630252004,
      "learning_rate": 1.0811904889859336e-06,
      "loss": 0.0041,
      "step": 1875
    },
    {
      "epoch": 0.5067004466964464,
      "grad_norm": 0.04185729846358299,
      "learning_rate": 6.956098498760389e-07,
      "loss": 0.005,
      "step": 1900
    },
    {
      "epoch": 0.5133675578371891,
      "grad_norm": 0.13528883457183838,
      "learning_rate": 3.9426493427611177e-07,
      "loss": 0.0054,
      "step": 1925
    },
    {
      "epoch": 0.5200346689779318,
      "grad_norm": 0.20430146157741547,
      "learning_rate": 1.776705849195037e-07,
      "loss": 0.0044,
      "step": 1950
    },
    {
      "epoch": 0.5267017801186745,
      "grad_norm": 0.1579304337501526,
      "learning_rate": 4.619684961881254e-08,
      "loss": 0.004,
      "step": 1975
    },
    {
      "epoch": 0.5333688912594173,
      "grad_norm": 0.18479418754577637,
      "learning_rate": 6.834904537900144e-11,
      "loss": 0.0048,
      "step": 2000
    }
  ],
  "logging_steps": 25,
  "max_steps": 2000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5024539213824000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
